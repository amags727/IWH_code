# Setup -------------------------------------------------------------------
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64',
'readstata13','reshape2','countrycode','sf', 'units',
'maps', 'airportr', 'geosphere', 'riem', 'fixest', 'gt', 'modelsummary', 'ggpubr', 'patchwork')
lapply(packages, library, character.only = T)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd('../..')
NA_sum = function(x){
ifelse(all(is.na(x)), NA,sum(x, na.rm = T))
}
merge_list = function(data_list){
output = data_list[[1]]
for (i in 2:length(data_list)){
output = merge(output, data_list[[i]], all = T)
}
return(output)
}
exclude_from = function(base_list, exclude_elements){
return(base_list[!base_list %in% exclude_elements])
}
# analysis ----------------------------------------------------------------
refugee_flows = fread('Data/processed/estimation_datasets/refugeee_pair_instrumented.csv') %>%
mutate( residual = sinh(log_push_pred) - flow)
patents_siren = fread('1_patent/patents_from_siren.csv')
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('0_input_data/helper_functions.R')
numCores <- 1  # Detect the number of cores
cl <- makeCluster(numCores)  # Create a cluster
registerDoParallel(cl)  # Register the cluster
patents_siren = fread('1_patent/patents_from_siren.csv')
View(patents_siren)
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('0_input_data/helper_functions.R')
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
file_list = dir('1_patent/results_time')
patent_from_dates_raw = lapply(file_list, function(file){
file = fread(file.path('1_patent/results_time', file))
file = file %>% mutate(country = substr(file$PUBN,10,11),
across(c(DEPN, PUBN),  ~(sub(".*<doc-number>(\\d+)</doc-number>.*", "\\1", .)))) %>%
select(country,everything())
}) %>% rbindlist(use.names = T, fill = T)
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('0_input_data/helper_functions.R')
numCores <- 1 # detectCores()  # Detect the number of cores
cl <- makeCluster(numCores)  # Create a cluster
registerDoParallel(cl)  # Register the cluster
clusterExport(cl, exclude_from(ls(), 'cl'))
clusterEvalQ(cl, {lapply(packages,library, character.only = T)})
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
abort()
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
abort()
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
abort()
debugSource("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/5_scrape_patent_and_trademark_data.R", echo=TRUE)
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('0_input_data/helper_functions.R')
abort()
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('0_input_data/helper_functions.R')
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
user_name = login_info$user_name[i]
password = login_info$password[i]
type
failed_attempts = data.frame(value = 0); fwrite(failed_attempts, file.path(type,'failed_attempts.csv'))
failed_attempts
fread(file.path(type,'failed_attempts.csv')) %>% pull(value) <3
fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
dates <- fread(file.path(type,'dates.csv')) %>% mutate(across(c(start_dates, end_dates), ~as.Date(., format = "%m/%d/%y")))
dates
i = which(dates$completed == 0)[1]
i
date_string =  paste0('[DEPD=', format(dates$start_dates[i], "%Y%m%d"), ":",
format(dates$end_dates[i], "%Y%m%d"),']')
if (type =="1_patent"){
date_string =  paste0('[DEPD=', format(dates$start_dates[i], "%Y%m%d"), ":",
format(dates$end_dates[i], "%Y%m%d"),']')
}else{
date_string =  paste0('[ApplicationDate=', format(dates$start_dates[i], "%Y%m%d"), ":",
format(dates$end_dates[i], "%Y%m%d"),']')
}
date_string
system2('0_input_data/scraping_script.sh', args =  c(user_name, password,type,date_string))
xml_data = read_xml(paste0(type,'_scraping_output.xml'))
View(xml_data)
length(xml_find_all(xml_data, "//metadata"))
length(xml_find_all(xml_data, "//metadata")) != 1
reset_failed_attempts(type)
nodes <- xml_find_all(xml_data, "//result")
nodes
length(nodes) != 10000
nodes_to_df(nodes)
fwrite(nodes_to_df(nodes), paste0(type, '/results_time/','results_', i, '.csv'))
dates = data.frame(start_dates = seq(ymd("1990-01-01"), ymd("2023-01-01"), by="1 months"),
end_dates = seq(ymd("1990-02-01"), ymd("2023-02-01"), by="1 months"),
completed = 0)
fwrite(dates,'1_patent/dates.csv')
fwrite(dates,'2_trademark/dates.csv')
type = '2_trademark'
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
i = which(login_info$availability == 0)[1]
if(is.na(i)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
login_info$availability[i] = 1
fwrite(login_info,'0_input_data/login_info.csv')
scraping_iteration_dates_only(login_info$user_name[i],
login_info$password[i], type)
print(paste('login num:', i))
}
keep_going = fread(file.path(type, 'dates.csv')) %>% pull(completed) %>% min() == 0
}
siren_numbers =fread('0_input_data/StockUniteLegaleHistorique_utf8 2.csv',
select = c('denominationUniteLegale', 'siren'),  colClasses = list(character = "siren"))
siren_numbers = siren_numbers[denominationUniteLegale!= ""]
siren_numbers = siren_numbers[!duplicated(siren)]
siren_numbers = siren_numbers %>% select(siren)
siren_numbers$category = numeric()
fwrite(siren_numbers, '1_patent/siren_numbers.csv')
fwrite(siren_numbers, '2_trademark/siren_numbers.csv')
dir('1_patent/results_siren')
dir('1_patent/results_siren') %>%str_replace(., "results_3", '') %>% str_replace(.,'.csv', '')
dir('1_patent/results_siren') %>%str_replace(., "results_", '') %>% str_replace(.,'.csv', '')
length(dir('1_patent/results_siren'))
if (length(dir('1_patent/results_siren')) > 0 )
if (length(dir('1_patent/results_siren')) > 0 ){
siren_with_patents = dir('1_patent/results_siren') %>%str_replace(., "results_", '') %>% str_replace(.,'.csv', '')
}
file_list = dir('1_patent/results_time')
patent_from_dates_raw = lapply(file_list, function(file){
file = fread(file.path('1_patent/results_time', file))
file = file %>% mutate(country = substr(file$PUBN,10,11),
across(c(DEPN, PUBN),  ~(sub(".*<doc-number>(\\d+)</doc-number>.*", "\\1", .)))) %>%
select(country,everything())
}) %>% rbindlist(use.names = T, fill = T) %>% unique()
fwrite(patent_from_dates_raw, '1_patent/patents_from_time.csv')
str_cleaning = function(x){
x %>% str_trim(.) %>% str_replace(., "&apos;", "'") %>% toupper(.) %>% stri_trans_general(.,"Latin-ASCII")
}
if (length(dir('1_patent/results_siren')) > 0 ){
siren_with_patents = dir('1_patent/results_siren') %>%str_replace(., "results_", '') %>% str_replace(.,'.csv', '')
}
if (length(dir('1_patent/results_siren')) > 0 ){
siren_with_patents = dir('1_patent/results_siren') %>%str_replace(., "results_", '') %>% str_replace(.,'.csv', '')
} else{siren_with_patents = ""}
siren_with_patents = NA
siren_with_patents = c()
if (length(dir('1_patent/results_siren')) > 0 ){
siren_with_patents = dir('1_patent/results_siren') %>%str_replace(., "results_", '') %>% str_replace(.,'.csv', '')
} else{siren_with_patents = c()}
siren_with_patents = c()
c('hi', siren_with_patents)
siren_with_patents = dir('1_patent/results_siren') %>%str_replace(., "results_", '') %>% str_replace(.,'.csv', '')
siren_numbers =fread('0_input_data/StockUniteLegaleHistorique_utf8 2.csv',
select = c('denominationUniteLegale', 'siren'),  colClasses = list(character = "siren")) %>%
rename(DENE = denominationUniteLegale)
siren_numbers[, DENE := str_cleaning(DENE)]
siren_numbers = siren_numbers[!duplicated(DENE) & DENE!= ""]
patents= fread( '1_patent/patents_from_time.csv')
patents_unnested  = patents %>% rename(DENE_list = DENE)
patents_unnested = patents_unnested[, DENE := str_split(str_trim(DENE_list), "\\s*,\\s*")] %>%
unnest(DENE) %>% as.data.table()
patents_unnested[, DENE :=  str_cleaning(DENE)]
patents_unnested = patents_unnested %>% merge(.,  siren_numbers, all.x = T)
patents_unnested %>% pull(siren) %>% unique()
patents_unnested %>% select(siren) %>% unique() %>% filter(!is.na(siren), siren!="")
patents_unnested %>% select(siren) %>% unique() %>% filter(!is.na(siren), siren!="") %>% rbind(.,siren_with_patents)
patents_unnested %>% filter(!is.na(siren), siren!="") %>% pull(siren) %>% unique() %>% c(.,siren_with_patents)
patents_unnested %>% filter(!is.na(siren), siren!="") %>% pull(siren) %>% unique() %>% c(.,siren_with_patents) %>% unique()
type = '1_patent'
keep_going = any(is.na(fread(file.path(type,'siren_numbers.csv'))[['category']]))
while (keep_going){
login_info = fread('0_input_data/login_info.csv')
chosen_index = which(login_info$availability == 0)[1]
if(is.na(chosen_index)){ # if no available nodes just reset those on cool-down and try again.
login_info$availability = 0
fwrite(login_info,'0_input_data/login_info.csv')
} else{
scraping_iteration(login_info$user_name[chosen_index],
login_info$password[chosen_index], type)
login_info$availability[chosen_index] = 1
fwrite(login_info,'0_input_data/login_info.csv')
print(paste('login num:', chosen_index))
}
keep_going = any(is.na(fread(file.path(type,'siren_numbers.csv'))[['category']]))
}
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64', 'xml2',
'doParallel', 'foreach', 'tictoc', 'R.utils', 'stringi')
lapply(packages, function(package){
tryCatch({ library(package, character.only = T)},error = function(cond){
install.packages(package);library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('0_input_data/helper_functions.R')
counter <- readRDS("~/Library/CloudStorage/GoogleDrive-amagnuson@g.harvard.edu/My Drive/Grad School/8) all projects/Trade/IWH/IWH_code/3_patent_scraping/2_trademark/counter.RDS")
tm_counter <- readRDS("3_patent_scraping/2_trademark/counter.RDS")
tm_counter <- readRDS("3_patent_scraping/2_trademark/counter.RDS")
